{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1w8D9jEm3hKCN82Uhk4U3bFBGYaAq13di",
      "authorship_tag": "ABX9TyORJ8C2WGrl1SzVShETH7mw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goldwyns/EEG_Quaternion/blob/main/Feature_Comparision_n_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.signal import detrend, butter, filtfilt\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.linalg import toeplitz\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score, matthews_corrcoef, roc_auc_score\n",
        "\n",
        "# Base paths with labels\n",
        "base_paths = {\n",
        "    's': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/s/S/\",\n",
        "    'z': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/z/Z/\",\n",
        "    'o': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/o/O/\",\n",
        "    'f': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/f/F/\",\n",
        "    'n': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/n/N/\"\n",
        "}\n",
        "\n",
        "# Load EEG Data\n",
        "def load_eeg_data(base_path):\n",
        "    print(f\"Loading EEG data from {base_path}\")\n",
        "    eeg_data = []\n",
        "    for file_name in os.listdir(base_path):\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            file_path = os.path.join(base_path, file_name)\n",
        "            data = np.loadtxt(file_path)\n",
        "            eeg_data.append(data)\n",
        "    if len(eeg_data) == 0:\n",
        "        raise ValueError(f\"No data found in directory: {base_path}\")\n",
        "    return np.concatenate(eeg_data)\n",
        "\n",
        "# Preprocess EEG signal\n",
        "def preprocess_signal(signal, lowcut=0.5, highcut=60.0, fs=173.61):\n",
        "    # print(\"Preprocessing EEG signal\")\n",
        "    signal_detrended = detrend(signal)\n",
        "    nyquist = 0.5 * fs\n",
        "    if lowcut >= highcut:\n",
        "        raise ValueError(\"Lowcut frequency must be less than highcut frequency.\")\n",
        "    if lowcut <= 0 or highcut >= nyquist:\n",
        "        raise ValueError(f\"Lowcut must be > 0 and highcut must be < Nyquist frequency ({nyquist} Hz).\")\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(1, [low, high], btype='band')\n",
        "    signal_filtered = filtfilt(b, a, signal_detrended)\n",
        "    scaler = StandardScaler()\n",
        "    signal_normalized = scaler.fit_transform(signal_filtered.reshape(-1, 1)).flatten()\n",
        "    return signal_normalized\n",
        "\n",
        "# Segment and preprocess data before splitting\n",
        "def segment_signal(signal, fs=173.61, window_duration=2.0, overlap_duration=1.0):\n",
        "    window_size = int(window_duration * fs)\n",
        "    overlap = int(overlap_duration * fs)\n",
        "    step = window_size - overlap\n",
        "    segments = []\n",
        "    for start in range(0, len(signal) - window_size + 1, step):\n",
        "        segment = signal[start:start + window_size]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "def segment_and_preprocess(data, label, fs=173.61, window_duration=2.0, overlap_duration=1.0):\n",
        "    print(f\"Segmenting and preprocessing data for label: {label}\")\n",
        "    segments, labels = [], []\n",
        "    segmented_signals = segment_signal(data, fs, window_duration, overlap_duration)\n",
        "    for segment in segmented_signals:\n",
        "        preprocessed_segment = preprocess_signal(segment, lowcut=0.5, highcut=60.0, fs=fs)\n",
        "        segments.append(preprocessed_segment)\n",
        "        labels.append(label)\n",
        "    return segments, labels\n",
        "\n",
        "# Feature extraction functions (using previously defined functions)\n",
        "def extract_normal_features(segment):\n",
        "    return [np.mean(segment), np.var(segment), skew(segment), kurtosis(segment), np.median(segment)]\n",
        "\n",
        "def extract_lpc_features(segment, order=10):\n",
        "    autocorr = np.correlate(segment, segment, mode='full')\n",
        "    autocorr = autocorr[autocorr.size // 2:]\n",
        "    R = toeplitz(autocorr[:order])\n",
        "    r = autocorr[1:order + 1]\n",
        "    a = np.linalg.solve(R, -r)\n",
        "    a = np.hstack([1, a])\n",
        "    return [np.mean(a), np.var(a), skew(a), kurtosis(a), np.median(a)]\n",
        "\n",
        "def extract_cepstral_features(segment, num_coefficients=13):\n",
        "    spectrum = np.fft.fft(segment)\n",
        "    log_spectrum = np.log(np.abs(spectrum) + 1e-8)\n",
        "    cepstrum = np.fft.ifft(log_spectrum).real\n",
        "    coefficients = cepstrum[:num_coefficients]\n",
        "    return [np.mean(coefficients), np.var(coefficients), skew(coefficients), kurtosis(coefficients), np.median(coefficients)]\n",
        "\n",
        "def extract_lattice_features(segment, order=10):\n",
        "    from scipy.signal import lfilter\n",
        "    from numpy.linalg import lstsq\n",
        "    x = segment\n",
        "    y = lfilter([1], [1] + [-0.9], x)\n",
        "    a, res, rank, s = lstsq(toeplitz(y[:-1], x[:1]), y[1:], rcond=None)  # Updated with rcond=None\n",
        "    return [np.mean(a), np.var(a), skew(a), kurtosis(a), np.median(a)]\n",
        "\n",
        "def extract_inverse_filter_features(segment, order=10):\n",
        "    from statsmodels.tsa.ar_model import AutoReg\n",
        "    model = AutoReg(segment, lags=order, old_names=False)\n",
        "    model_fit = model.fit()\n",
        "    coefficients = model_fit.params\n",
        "    return [np.mean(coefficients), np.var(coefficients), skew(coefficients), kurtosis(coefficients), np.median(coefficients)]\n",
        "\n",
        "def extract_spectral_features(segment, order=10):\n",
        "    from spectrum import aryule\n",
        "    _, rho, ref_coeffs = aryule(segment, order)\n",
        "    return [np.mean(ref_coeffs), np.var(ref_coeffs), skew(ref_coeffs), kurtosis(ref_coeffs), np.median(ref_coeffs)]\n",
        "\n",
        "def extract_features_by_type(segment, feature_type):\n",
        "    if feature_type == 'normal':\n",
        "        return extract_normal_features(segment)\n",
        "    elif feature_type == 'lpc':\n",
        "        return extract_lpc_features(segment)\n",
        "    elif feature_type == 'cepstral':\n",
        "        return extract_cepstral_features(segment)\n",
        "    elif feature_type == 'lattice':\n",
        "        return extract_lattice_features(segment)\n",
        "    elif feature_type == 'inverse_filter':\n",
        "        return extract_inverse_filter_features(segment)\n",
        "    elif feature_type == 'spectral':\n",
        "        return extract_spectral_features(segment)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid feature type\")\n",
        "\n",
        "def extract_features_from_segments(segments, feature_type):\n",
        "    features = [extract_features_by_type(segment, feature_type) for segment in segments]\n",
        "    return np.array(features)\n"
      ],
      "metadata": {
        "id": "w230VkRXeW8B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Neural Network Model Definitions**"
      ],
      "metadata": {
        "id": "lGTsHMF7edcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Bidirectional, Flatten, Dropout, Input, Layer, MultiHeadAttention, LayerNormalization, Embedding\n",
        "\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def create_bi_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64)))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def create_gru_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(GRU(64, return_sequences=True))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "WshoqH3ceZ5g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransformerBlock Implementation"
      ],
      "metadata": {
        "id": "ayV6nMATerNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attn_output = self.att(inputs, inputs, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "def create_transformer_model(input_shape, embed_dim=32, num_heads=2, ff_dim=32):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-X8lTz1OeqL_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capsule Network Implementation\n"
      ],
      "metadata": {
        "id": "9fq9UliIevKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsules, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsules = dim_capsules\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.num_capsules * self.dim_capsules),\n",
        "                                      initializer='glorot_uniform', trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Ensure inputs have a valid shape\n",
        "        if inputs.shape[1] is None or inputs.shape[2] is None:\n",
        "            raise ValueError(\"Input tensor must have defined shape for all dimensions except batch size.\")\n",
        "\n",
        "        inputs_expand = tf.expand_dims(inputs, axis=2)\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, 1, self.num_capsules * self.dim_capsules, 1])\n",
        "        inputs_hat = tf.map_fn(lambda x: tf.matmul(self.kernel, x), elems=inputs_tiled)\n",
        "        inputs_hat_reshaped = tf.reshape(inputs_hat, [-1, inputs.shape[1], self.num_capsules, self.dim_capsules])\n",
        "        b = tf.zeros(shape=[inputs.shape[0], inputs.shape[1], self.num_capsules])\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=-1)\n",
        "            s = tf.reduce_sum(tf.multiply(c, inputs_hat_reshaped), axis=1)\n",
        "            v = self.squash(s)\n",
        "            if i < self.routings - 1:\n",
        "                b = b + tf.reduce_sum(tf.multiply(inputs_hat_reshaped, tf.expand_dims(v, axis=1)), axis=-1)\n",
        "\n",
        "        return v\n",
        "\n",
        "    def squash(self, s):\n",
        "        s_norm = tf.norm(s, axis=-1, keepdims=True)\n",
        "        return (s_norm / (1 + s_norm ** 2)) * (s / s_norm)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1], self.num_capsules, self.dim_capsules)\n",
        "\n",
        "def create_capsule_model(input_shape, num_capsules=10, dim_capsules=16, routings=3):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    conv_layer = layers.Conv1D(256, kernel_size=3, strides=1, padding='valid', activation='relu')(inputs)\n",
        "    primary_capsules = layers.Conv1D(256, kernel_size=3, strides=2, padding='valid')(conv_layer)\n",
        "    primary_capsules = layers.Reshape(target_shape=[-1, dim_capsules])(primary_capsules)\n",
        "    capsule_layer = CapsuleLayer(num_capsules=num_capsules, dim_capsules=dim_capsules, routings=routings)(primary_capsules)\n",
        "    capsule_layer = layers.Flatten()(capsule_layer)\n",
        "    capsule_layer = layers.Dense(32, activation='relu')(capsule_layer)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(capsule_layer)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8DJi5CN9euMW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training and Evaluation\n"
      ],
      "metadata": {
        "id": "SFYSO4GCez-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "def run_binary_classification_nn(class1, class2):\n",
        "    all_segments, all_labels = [], []\n",
        "    for label in [class1, class2]:\n",
        "        path = base_paths[label]\n",
        "        eeg_data = load_eeg_data(path)\n",
        "        segments, labels = segment_and_preprocess(eeg_data, label)\n",
        "        all_segments.extend(segments)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    label_mapping = {class1: 0, class2: 1}\n",
        "    all_labels = [label_mapping[label] for label in all_labels]\n",
        "\n",
        "    # Define feature types\n",
        "    feature_types = ['normal', 'lpc', 'cepstral', 'inverse_filter', 'spectral']\n",
        "\n",
        "    # Initialize results\n",
        "    all_results = {}\n",
        "\n",
        "    for feature_type in feature_types:\n",
        "        # Extract features from segments\n",
        "        features = extract_features_from_segments(all_segments, feature_type)\n",
        "\n",
        "        # Handle missing values using SimpleImputer\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        features = imputer.fit_transform(features)\n",
        "\n",
        "        # Pad sequences if necessary\n",
        "        X = pad_sequences(features, maxlen=10, dtype='float32', padding='post', truncating='post')\n",
        "        X = X.reshape(len(X), X.shape[1], 1)\n",
        "\n",
        "        # Convert all_labels to a NumPy array\n",
        "        all_labels = np.array(all_labels)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n",
        "\n",
        "        input_shape = X_train.shape[1:]\n",
        "\n",
        "        # Define the neural network models\n",
        "        models = {\n",
        "            'LSTM': create_lstm_model(input_shape),\n",
        "            'Bi-LSTM': create_bi_lstm_model(input_shape),\n",
        "            'GRU': create_gru_model(input_shape),\n",
        "            'Transformer': create_transformer_model(input_shape),\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            print(f\"Training {name} model with {feature_type} features\")\n",
        "            model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
        "            y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
        "            specificity = recall_score(y_test, y_pred, pos_label=0)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "            mcc = matthews_corrcoef(y_test, y_pred)\n",
        "            y_prob = model.predict(X_test).flatten()\n",
        "            auc = roc_auc_score(y_test, y_prob)\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "            results[name] = {\n",
        "                'Accuracy': accuracy,\n",
        "                'Sensitivity': sensitivity,\n",
        "                'Specificity': specificity,\n",
        "                'F1 Score': f1,\n",
        "                'Matthews Coefficient': mcc,\n",
        "                'AUC': auc,\n",
        "                'True Positive': tp,\n",
        "                'True Negative': tn,\n",
        "                'False Positive': fp,\n",
        "                'False Negative': fn\n",
        "            }\n",
        "\n",
        "        all_results[feature_type] = results\n",
        "\n",
        "    return all_results\n"
      ],
      "metadata": {
        "id": "Sdxz1F4MezDx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete Display Results Function\n"
      ],
      "metadata": {
        "id": "WL9JpNV6fA_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(all_results, class1, class2):\n",
        "    print(f\"\\nClassification Results for {class1} vs {class2}:\\n\")\n",
        "    for feature_type, results in all_results.items():\n",
        "        print(f\"Feature Type: {feature_type}\")\n",
        "        for name, metrics in results.items():\n",
        "            print(f\"Classifier: {name}\")\n",
        "            print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "            print(f\"Sensitivity (Recall for Positive Class): {metrics['Sensitivity']:.4f}\")\n",
        "            print(f\"Specificity (Recall for Negative Class): {metrics['Specificity']:.4f}\")\n",
        "            print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
        "            print(f\"Matthews Correlation Coefficient: {metrics['Matthews Coefficient']:.4f}\")\n",
        "            print(f\"AUC: {metrics['AUC']:.4f}\")\n",
        "            print(f\"True Positives: {metrics['True Positive']}\")\n",
        "            print(f\"True Negatives: {metrics['True Negative']}\")\n",
        "            print(f\"False Positives: {metrics['False Positive']}\")\n",
        "            print(f\"False Negatives: {metrics['False Negative']}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the classes you want to compare\n",
        "    class1 = 's'\n",
        "    class2 = 'z'\n",
        "\n",
        "    # Run the binary classification with neural network models\n",
        "    all_results = run_binary_classification_nn(class1, class2)\n",
        "\n",
        "    # Display the results\n",
        "    display_results(all_results, class1, class2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t4HalMEe3B2",
        "outputId": "f7ddb708-f741-4182-a858-68dd389fef43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EEG data from /content/drive/MyDrive/Database/Bonn Univ Dataset/s/S/\n",
            "Segmenting and preprocessing data for label: s\n",
            "Loading EEG data from /content/drive/MyDrive/Database/Bonn Univ Dataset/z/Z/\n",
            "Segmenting and preprocessing data for label: z\n",
            "Training LSTM model with normal features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5483 - loss: 0.6854 - val_accuracy: 0.6361 - val_loss: 0.6671\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training Bi-LSTM model with normal features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5470 - loss: 0.6831 - val_accuracy: 0.6042 - val_loss: 0.6703\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Training GRU model with normal features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5341 - loss: 0.6883 - val_accuracy: 0.5896 - val_loss: 0.6743\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Transformer model with normal features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4973 - loss: 0.6932 - val_accuracy: 0.4927 - val_loss: 0.6932\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Training LSTM model with lpc features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5791 - loss: 0.6633 - val_accuracy: 0.8048 - val_loss: 0.4698\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Bi-LSTM model with lpc features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6082 - loss: 0.6293 - val_accuracy: 0.6879 - val_loss: 0.6092\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Training GRU model with lpc features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6198 - loss: 0.6424 - val_accuracy: 0.8035 - val_loss: 0.4548\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Transformer model with lpc features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4865 - loss: 0.6932 - val_accuracy: 0.4927 - val_loss: 0.6932\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Training LSTM model with cepstral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5111 - loss: 0.6904 - val_accuracy: 0.5538 - val_loss: 0.6866\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training Bi-LSTM model with cepstral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5058 - loss: 0.6872 - val_accuracy: 0.5551 - val_loss: 0.7160\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Training GRU model with cepstral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5126 - loss: 0.6893 - val_accuracy: 0.6441 - val_loss: 0.6660\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Transformer model with cepstral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.4873 - loss: 0.6932 - val_accuracy: 0.4927 - val_loss: 0.6932\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Training LSTM model with inverse_filter features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8583 - loss: 0.4547 - val_accuracy: 0.9084 - val_loss: 0.2443\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Training Bi-LSTM model with inverse_filter features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7045 - loss: 0.4796 - val_accuracy: 0.9057 - val_loss: 0.2389\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training GRU model with inverse_filter features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7983 - loss: 0.5051 - val_accuracy: 0.9124 - val_loss: 0.2451\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Transformer model with inverse_filter features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.5035 - loss: 0.6932 - val_accuracy: 0.5073 - val_loss: 0.6931\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training LSTM model with spectral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5185 - loss: 0.6882 - val_accuracy: 0.5405 - val_loss: 0.6888\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Bi-LSTM model with spectral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5438 - loss: 0.6867 - val_accuracy: 0.5618 - val_loss: 0.6864\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Training GRU model with spectral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5274 - loss: 0.6895 - val_accuracy: 0.5591 - val_loss: 0.6863\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Transformer model with spectral features\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.4874 - loss: 0.6932 - val_accuracy: 0.4927 - val_loss: 0.6932\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\n",
            "Classification Results for s vs z:\n",
            "\n",
            "Feature Type: normal\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.6146\n",
            "Sensitivity (Recall for Positive Class): 0.7197\n",
            "Specificity (Recall for Negative Class): 0.5096\n",
            "F1 Score: 0.6513\n",
            "Matthews Correlation Coefficient: 0.2345\n",
            "AUC: 0.6441\n",
            "True Positives: 339\n",
            "True Negatives: 240\n",
            "False Positives: 231\n",
            "False Negatives: 132\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.6242\n",
            "Sensitivity (Recall for Positive Class): 0.8726\n",
            "Specificity (Recall for Negative Class): 0.3758\n",
            "F1 Score: 0.6990\n",
            "Matthews Correlation Coefficient: 0.2862\n",
            "AUC: 0.6197\n",
            "True Positives: 411\n",
            "True Negatives: 177\n",
            "False Positives: 294\n",
            "False Negatives: 60\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.5743\n",
            "Sensitivity (Recall for Positive Class): 0.7622\n",
            "Specificity (Recall for Negative Class): 0.3864\n",
            "F1 Score: 0.6416\n",
            "Matthews Correlation Coefficient: 0.1604\n",
            "AUC: 0.6195\n",
            "True Positives: 359\n",
            "True Negatives: 182\n",
            "False Positives: 289\n",
            "False Negatives: 112\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 1.0000\n",
            "Specificity (Recall for Negative Class): 0.0000\n",
            "F1 Score: 0.6667\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 471\n",
            "True Negatives: 0\n",
            "False Positives: 471\n",
            "False Negatives: 0\n",
            "--------------------------------------------------\n",
            "Feature Type: lpc\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.8227\n",
            "Sensitivity (Recall for Positive Class): 0.8259\n",
            "Specificity (Recall for Negative Class): 0.8195\n",
            "F1 Score: 0.8233\n",
            "Matthews Correlation Coefficient: 0.6454\n",
            "AUC: 0.8938\n",
            "True Positives: 389\n",
            "True Negatives: 386\n",
            "False Positives: 85\n",
            "False Negatives: 82\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.7155\n",
            "Sensitivity (Recall for Positive Class): 0.9830\n",
            "Specificity (Recall for Negative Class): 0.4480\n",
            "F1 Score: 0.7755\n",
            "Matthews Correlation Coefficient: 0.5102\n",
            "AUC: 0.8883\n",
            "True Positives: 463\n",
            "True Negatives: 211\n",
            "False Positives: 260\n",
            "False Negatives: 8\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.8333\n",
            "Sensitivity (Recall for Positive Class): 0.8514\n",
            "Specificity (Recall for Negative Class): 0.8153\n",
            "F1 Score: 0.8363\n",
            "Matthews Correlation Coefficient: 0.6671\n",
            "AUC: 0.8845\n",
            "True Positives: 401\n",
            "True Negatives: 384\n",
            "False Positives: 87\n",
            "False Negatives: 70\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 1.0000\n",
            "Specificity (Recall for Negative Class): 0.0000\n",
            "F1 Score: 0.6667\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 471\n",
            "True Negatives: 0\n",
            "False Positives: 471\n",
            "False Negatives: 0\n",
            "--------------------------------------------------\n",
            "Feature Type: cepstral\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.5658\n",
            "Sensitivity (Recall for Positive Class): 0.5839\n",
            "Specificity (Recall for Negative Class): 0.5478\n",
            "F1 Score: 0.5735\n",
            "Matthews Correlation Coefficient: 0.1317\n",
            "AUC: 0.5248\n",
            "True Positives: 275\n",
            "True Negatives: 258\n",
            "False Positives: 213\n",
            "False Negatives: 196\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.5573\n",
            "Sensitivity (Recall for Positive Class): 0.5605\n",
            "Specificity (Recall for Negative Class): 0.5541\n",
            "F1 Score: 0.5587\n",
            "Matthews Correlation Coefficient: 0.1147\n",
            "AUC: 0.5254\n",
            "True Positives: 264\n",
            "True Negatives: 261\n",
            "False Positives: 210\n",
            "False Negatives: 207\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.6380\n",
            "Sensitivity (Recall for Positive Class): 0.5605\n",
            "Specificity (Recall for Negative Class): 0.7155\n",
            "F1 Score: 0.6076\n",
            "Matthews Correlation Coefficient: 0.2794\n",
            "AUC: 0.6688\n",
            "True Positives: 264\n",
            "True Negatives: 337\n",
            "False Positives: 134\n",
            "False Negatives: 207\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 1.0000\n",
            "Specificity (Recall for Negative Class): 0.0000\n",
            "F1 Score: 0.6667\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 471\n",
            "True Negatives: 0\n",
            "False Positives: 471\n",
            "False Negatives: 0\n",
            "--------------------------------------------------\n",
            "Feature Type: inverse_filter\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.8981\n",
            "Sensitivity (Recall for Positive Class): 0.9639\n",
            "Specificity (Recall for Negative Class): 0.8323\n",
            "F1 Score: 0.9044\n",
            "Matthews Correlation Coefficient: 0.8032\n",
            "AUC: 0.9408\n",
            "True Positives: 454\n",
            "True Negatives: 392\n",
            "False Positives: 79\n",
            "False Negatives: 17\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.8970\n",
            "Sensitivity (Recall for Positive Class): 0.9575\n",
            "Specificity (Recall for Negative Class): 0.8365\n",
            "F1 Score: 0.9029\n",
            "Matthews Correlation Coefficient: 0.7999\n",
            "AUC: 0.9442\n",
            "True Positives: 451\n",
            "True Negatives: 394\n",
            "False Positives: 77\n",
            "False Negatives: 20\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.9034\n",
            "Sensitivity (Recall for Positive Class): 0.9788\n",
            "Specificity (Recall for Negative Class): 0.8280\n",
            "F1 Score: 0.9102\n",
            "Matthews Correlation Coefficient: 0.8161\n",
            "AUC: 0.9350\n",
            "True Positives: 461\n",
            "True Negatives: 390\n",
            "False Positives: 81\n",
            "False Negatives: 10\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 0.0000\n",
            "Specificity (Recall for Negative Class): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 0\n",
            "True Negatives: 471\n",
            "False Positives: 0\n",
            "False Negatives: 471\n",
            "--------------------------------------------------\n",
            "Feature Type: spectral\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.5393\n",
            "Sensitivity (Recall for Positive Class): 0.9384\n",
            "Specificity (Recall for Negative Class): 0.1401\n",
            "F1 Score: 0.6707\n",
            "Matthews Correlation Coefficient: 0.1304\n",
            "AUC: 0.6020\n",
            "True Positives: 442\n",
            "True Negatives: 66\n",
            "False Positives: 405\n",
            "False Negatives: 29\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.5584\n",
            "Sensitivity (Recall for Positive Class): 0.8938\n",
            "Specificity (Recall for Negative Class): 0.2229\n",
            "F1 Score: 0.6693\n",
            "Matthews Correlation Coefficient: 0.1575\n",
            "AUC: 0.6043\n",
            "True Positives: 421\n",
            "True Negatives: 105\n",
            "False Positives: 366\n",
            "False Negatives: 50\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.5669\n",
            "Sensitivity (Recall for Positive Class): 0.8514\n",
            "Specificity (Recall for Negative Class): 0.2824\n",
            "F1 Score: 0.6628\n",
            "Matthews Correlation Coefficient: 0.1627\n",
            "AUC: 0.5893\n",
            "True Positives: 401\n",
            "True Negatives: 133\n",
            "False Positives: 338\n",
            "False Negatives: 70\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 1.0000\n",
            "Specificity (Recall for Negative Class): 0.0000\n",
            "F1 Score: 0.6667\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 471\n",
            "True Negatives: 0\n",
            "False Positives: 471\n",
            "False Negatives: 0\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spectrum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDLT9tek1NEs",
        "outputId": "128f0c9f-4491-4579-a73c-f25377b67661"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spectrum\n",
            "  Downloading spectrum-0.9.0.tar.gz (231 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/231.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/231.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting easydev (from spectrum)\n",
            "  Downloading easydev-0.13.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from spectrum) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from spectrum) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from spectrum) (3.10.0)\n",
            "Collecting colorama<0.5.0,>=0.4.6 (from easydev->spectrum)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlog<7.0.0,>=6.8.2 (from easydev->spectrum)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev->spectrum)\n",
            "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum) (4.9.0)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum) (4.3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->spectrum) (1.17.0)\n",
            "Downloading easydev-0.13.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spectrum\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.9.0-cp311-cp311-linux_x86_64.whl size=236751 sha256=1217fe5b6ed7284f80222d9f8fb1f0f9c23f8c8b41a5c8cea70ee6f13aa91634\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/9c/de/eb558fbd03ea1540d3c908f23681f57f9d9e8c2a5cd08d6f42\n",
            "Successfully built spectrum\n",
            "Installing collected packages: line-profiler, colorlog, colorama, easydev, spectrum\n",
            "Successfully installed colorama-0.4.6 colorlog-6.9.0 easydev-0.13.3 line-profiler-4.2.0 spectrum-0.9.0\n"
          ]
        }
      ]
    }
  ]
}
