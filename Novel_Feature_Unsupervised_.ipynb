{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bYVveGy5-ve8o5SuhEX8D5HtpL2FIsws",
      "authorship_tag": "ABX9TyPXyfYayJ4DXwROdiaeIIlY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goldwyns/Epilepsy-Classification-Using-Novel-Feature-Set/blob/main/Feature_Selection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spectrum"
      ],
      "metadata": {
        "id": "mh3eNxv4lJh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887fe0bc-51fc-43a4-8e56-25913dd58c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spectrum\n",
            "  Downloading spectrum-0.9.0.tar.gz (231 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/231.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/231.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting easydev (from spectrum)\n",
            "  Downloading easydev-0.13.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from spectrum) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from spectrum) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from spectrum) (3.10.0)\n",
            "Collecting colorama<0.5.0,>=0.4.6 (from easydev->spectrum)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlog<7.0.0,>=6.8.2 (from easydev->spectrum)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev->spectrum)\n",
            "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum) (4.9.0)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum) (4.3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spectrum) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->spectrum) (1.17.0)\n",
            "Downloading easydev-0.13.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spectrum\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.9.0-cp311-cp311-linux_x86_64.whl size=236745 sha256=767e2df6622508c9f96cfd3011fcd8854cd5de4df1dd97f537403d9f6adc81d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/9c/de/eb558fbd03ea1540d3c908f23681f57f9d9e8c2a5cd08d6f42\n",
            "Successfully built spectrum\n",
            "Installing collected packages: line-profiler, colorlog, colorama, easydev, spectrum\n",
            "Successfully installed colorama-0.4.6 colorlog-6.9.0 easydev-0.13.3 line-profiler-4.2.0 spectrum-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.signal import detrend, butter, filtfilt\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.linalg import toeplitz\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score, matthews_corrcoef, roc_auc_score\n",
        "\n",
        "# Base paths with labels\n",
        "base_paths = {\n",
        "    's': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/s/S/\",\n",
        "    'z': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/z/Z/\",\n",
        "    'o': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/o/O/\",\n",
        "    'f': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/f/F/\",\n",
        "    'n': \"/content/drive/MyDrive/Database/Bonn Univ Dataset/n/N/\"\n",
        "}\n",
        "\n",
        "# Load EEG Data\n",
        "def load_eeg_data(base_path):\n",
        "    print(f\"Loading EEG data from {base_path}\")\n",
        "    eeg_data = []\n",
        "    file_count = 0\n",
        "    for file_name in os.listdir(base_path):\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            file_count += 1\n",
        "            file_path = os.path.join(base_path, file_name)\n",
        "            data = np.loadtxt(file_path)\n",
        "            if len(data) > 4097:\n",
        "                print(f\"File {file_name} has more than 4097 data points: {len(data)}\")\n",
        "            eeg_data.append(data)\n",
        "    print(f\"Number of files loaded: {file_count}\")\n",
        "    if len(eeg_data) == 0:\n",
        "        raise ValueError(f\"No data found in directory: {base_path}\")\n",
        "    return eeg_data\n",
        "\n",
        "# Preprocess EEG signal\n",
        "def preprocess_signal(signal, lowcut=0.5, highcut=60.0, fs=173.61):\n",
        "    # print(\"Preprocessing EEG signal\")\n",
        "    signal_detrended = detrend(signal)\n",
        "    nyquist = 0.5 * fs\n",
        "    if lowcut >= highcut:\n",
        "        raise ValueError(\"Lowcut frequency must be less than highcut frequency.\")\n",
        "    if lowcut <= 0 or highcut >= nyquist:\n",
        "        raise ValueError(f\"Lowcut must be > 0 and highcut must be < Nyquist frequency ({nyquist} Hz).\")\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(1, [low, high], btype='band')\n",
        "    signal_filtered = filtfilt(b, a, signal_detrended)\n",
        "    scaler = StandardScaler()\n",
        "    signal_normalized = scaler.fit_transform(signal_filtered.reshape(-1, 1)).flatten()\n",
        "    return signal_normalized\n",
        "\n",
        "# Segment and preprocess data before splitting\n",
        "def segment_signal(signal, fs=173.61, window_duration=2.0, overlap_duration=1.0):\n",
        "    window_size = int(window_duration * fs)\n",
        "    overlap = int(overlap_duration * fs)\n",
        "    step = window_size - overlap\n",
        "    segments = []\n",
        "    for start in range(0, len(signal) - window_size + 1, step):\n",
        "        segment = signal[start:start + window_size]\n",
        "        segments.append(segment)\n",
        "    print(f\"Number of segments created: {len(segments)}\")\n",
        "    return segments\n",
        "\n",
        "def segment_and_preprocess(data, label, fs=173.61, window_duration=2.0, overlap_duration=1.0):\n",
        "    print(f\"Segmenting and preprocessing data for label: {label}\")\n",
        "    segments, labels = [], []\n",
        "    for single_data in data:\n",
        "        segmented_signals = segment_signal(single_data, fs, window_duration, overlap_duration)\n",
        "        for segment in segmented_signals:\n",
        "            preprocessed_segment = preprocess_signal(segment, lowcut=0.5, highcut=60.0, fs=fs)\n",
        "            segments.append(preprocessed_segment)\n",
        "            labels.append(label)\n",
        "    return segments, labels\n",
        "\n",
        "# Feature extraction functions (using previously defined functions)\n",
        "def extract_normal_features(segment):\n",
        "    return [np.mean(segment), np.var(segment), skew(segment), kurtosis(segment), np.median(segment)]\n",
        "\n",
        "def extract_lpc_features(segment, order=10):\n",
        "    autocorr = np.correlate(segment, segment, mode='full')\n",
        "    autocorr = autocorr[autocorr.size // 2:]\n",
        "    R = toeplitz(autocorr[:order])\n",
        "    r = autocorr[1:order + 1]\n",
        "    a = np.linalg.solve(R, -r)\n",
        "    a = np.hstack([1, a])\n",
        "    return [np.mean(a), np.var(a), skew(a), kurtosis(a), np.median(a)]\n",
        "\n",
        "def extract_cepstral_features(segment, num_coefficients=13):\n",
        "    spectrum = np.fft.fft(segment)\n",
        "    log_spectrum = np.log(np.abs(spectrum) + 1e-8)\n",
        "    cepstrum = np.fft.ifft(log_spectrum).real\n",
        "    coefficients = cepstrum[:num_coefficients]\n",
        "    return [np.mean(coefficients), np.var(coefficients), skew(coefficients), kurtosis(coefficients), np.median(coefficients)]\n",
        "\n",
        "def extract_lattice_features(segment, order=10):\n",
        "    from scipy.signal import lfilter\n",
        "    from numpy.linalg import lstsq\n",
        "    x = segment\n",
        "    y = lfilter([1], [1] + [-0.9], x)\n",
        "    a, res, rank, s = lstsq(toeplitz(y[:-1], x[:1]), y[1:], rcond=None)  # Updated with rcond=None\n",
        "    return [np.mean(a), np.var(a), skew(a), kurtosis(a), np.median(a)]\n",
        "\n",
        "def extract_inverse_filter_features(segment, order=10):\n",
        "    from statsmodels.tsa.ar_model import AutoReg\n",
        "    model = AutoReg(segment, lags=order, old_names=False)\n",
        "    model_fit = model.fit()\n",
        "    coefficients = model_fit.params\n",
        "    return [np.mean(coefficients), np.var(coefficients), skew(coefficients), kurtosis(coefficients), np.median(coefficients)]\n",
        "\n",
        "def extract_spectral_features(segment, order=10):\n",
        "    from spectrum import aryule\n",
        "    _, rho, ref_coeffs = aryule(segment, order)\n",
        "    return [np.mean(ref_coeffs), np.var(ref_coeffs), skew(ref_coeffs), kurtosis(ref_coeffs), np.median(ref_coeffs)]\n",
        "\n",
        "def extract_features_by_type(segment, feature_type):\n",
        "    if feature_type == 'normal':\n",
        "        return extract_normal_features(segment)\n",
        "    elif feature_type == 'lpc':\n",
        "        return extract_lpc_features(segment)\n",
        "    elif feature_type == 'cepstral':\n",
        "        return extract_cepstral_features(segment)\n",
        "    elif feature_type == 'lattice':\n",
        "        return extract_lattice_features(segment)\n",
        "    elif feature_type == 'inverse_filter':\n",
        "        return extract_inverse_filter_features(segment)\n",
        "    elif feature_type == 'spectral':\n",
        "        return extract_spectral_features(segment)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid feature type\")\n",
        "\n",
        "def extract_features_from_segments(segments, feature_type):\n",
        "    features = [extract_features_by_type(segment, feature_type) for segment in segments]\n",
        "    return np.array(features)\n"
      ],
      "metadata": {
        "id": "w230VkRXeW8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Neural Network Model Definitions**"
      ],
      "metadata": {
        "id": "lGTsHMF7edcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Bidirectional, Flatten, Dropout, Input, Layer, MultiHeadAttention, LayerNormalization, Embedding\n",
        "\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def create_bi_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64)))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def create_gru_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(GRU(64, return_sequences=True))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "WshoqH3ceZ5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransformerBlock Implementation"
      ],
      "metadata": {
        "id": "ayV6nMATerNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attn_output = self.att(inputs, inputs, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "def create_transformer_model(input_shape, embed_dim=32, num_heads=2, ff_dim=32):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-X8lTz1OeqL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capsule Network Implementation\n"
      ],
      "metadata": {
        "id": "9fq9UliIevKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsules, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsules = dim_capsules\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.num_capsules * self.dim_capsules),\n",
        "                                      initializer='glorot_uniform', trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Ensure inputs have a valid shape\n",
        "        if inputs.shape[1] is None or inputs.shape[2] is None:\n",
        "            raise ValueError(\"Input tensor must have defined shape for all dimensions except batch size.\")\n",
        "\n",
        "        inputs_expand = tf.expand_dims(inputs, axis=2)\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, 1, self.num_capsules * self.dim_capsules, 1])\n",
        "        inputs_hat = tf.map_fn(lambda x: tf.matmul(self.kernel, x), elems=inputs_tiled)\n",
        "        inputs_hat_reshaped = tf.reshape(inputs_hat, [-1, inputs.shape[1], self.num_capsules, self.dim_capsules])\n",
        "        b = tf.zeros(shape=[inputs.shape[0], inputs.shape[1], self.num_capsules])\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=-1)\n",
        "            s = tf.reduce_sum(tf.multiply(c, inputs_hat_reshaped), axis=1)\n",
        "            v = self.squash(s)\n",
        "            if i < self.routings - 1:\n",
        "                b = b + tf.reduce_sum(tf.multiply(inputs_hat_reshaped, tf.expand_dims(v, axis=1)), axis=-1)\n",
        "\n",
        "        return v\n",
        "\n",
        "    def squash(self, s):\n",
        "        s_norm = tf.norm(s, axis=-1, keepdims=True)\n",
        "        return (s_norm / (1 + s_norm ** 2)) * (s / s_norm)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1], self.num_capsules, self.dim_capsules)\n",
        "\n",
        "def create_capsule_model(input_shape, num_capsules=10, dim_capsules=16, routings=3):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    conv_layer = layers.Conv1D(256, kernel_size=3, strides=1, padding='valid', activation='relu')(inputs)\n",
        "    primary_capsules = layers.Conv1D(256, kernel_size=3, strides=2, padding='valid')(conv_layer)\n",
        "    primary_capsules = layers.Reshape(target_shape=[-1, dim_capsules])(primary_capsules)\n",
        "    capsule_layer = CapsuleLayer(num_capsules=num_capsules, dim_capsules=dim_capsules, routings=routings)(primary_capsules)\n",
        "    capsule_layer = layers.Flatten()(capsule_layer)\n",
        "    capsule_layer = layers.Dense(32, activation='relu')(capsule_layer)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(capsule_layer)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8DJi5CN9euMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training and Evaluation\n"
      ],
      "metadata": {
        "id": "SFYSO4GCez-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "def run_binary_classification_nn(class1, class2):\n",
        "    all_segments, all_labels = [], []\n",
        "    for label in [class1, class2]:\n",
        "        path = base_paths[label]\n",
        "        eeg_data = load_eeg_data(path)\n",
        "        segments, labels = segment_and_preprocess(eeg_data, label)\n",
        "        all_segments.extend(segments)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    label_mapping = {class1: 0, class2: 1}\n",
        "    all_labels = [label_mapping[label] for label in all_labels]\n",
        "\n",
        "    # Define feature types\n",
        "    feature_types = ['normal', 'lpc', 'cepstral', 'inverse_filter', 'spectral']\n",
        "\n",
        "    # Initialize results\n",
        "    all_results = {}\n",
        "\n",
        "    for feature_type in feature_types:\n",
        "        # Extract features from segments\n",
        "        features = extract_features_from_segments(all_segments, feature_type)\n",
        "\n",
        "        # Handle missing values using SimpleImputer\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        features = imputer.fit_transform(features)\n",
        "\n",
        "        # Pad sequences if necessary\n",
        "        X = pad_sequences(features, maxlen=10, dtype='float32', padding='post', truncating='post')\n",
        "        X = X.reshape(len(X), X.shape[1], 1)\n",
        "\n",
        "        # Convert all_labels to a NumPy array\n",
        "        all_labels = np.array(all_labels)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n",
        "\n",
        "        input_shape = X_train.shape[1:]\n",
        "\n",
        "        # Define the neural network models\n",
        "        models = {\n",
        "            'LSTM': create_lstm_model(input_shape),\n",
        "            'Bi-LSTM': create_bi_lstm_model(input_shape),\n",
        "            'GRU': create_gru_model(input_shape),\n",
        "            'Transformer': create_transformer_model(input_shape),\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            print(f\"Training {name} model with {feature_type} features\")\n",
        "            model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "            y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
        "            specificity = recall_score(y_test, y_pred, pos_label=0)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "            mcc = matthews_corrcoef(y_test, y_pred)\n",
        "            y_prob = model.predict(X_test).flatten()\n",
        "            auc = roc_auc_score(y_test, y_prob)\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "            results[name] = {\n",
        "                'Accuracy': accuracy,\n",
        "                'Sensitivity': sensitivity,\n",
        "                'Specificity': specificity,\n",
        "                'F1 Score': f1,\n",
        "                'Matthews Coefficient': mcc,\n",
        "                'AUC': auc,\n",
        "                'True Positive': tp,\n",
        "                'True Negative': tn,\n",
        "                'False Positive': fp,\n",
        "                'False Negative': fn\n",
        "            }\n",
        "\n",
        "        all_results[feature_type] = results\n",
        "\n",
        "    return all_results\n"
      ],
      "metadata": {
        "id": "Sdxz1F4MezDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete Display Results Function\n"
      ],
      "metadata": {
        "id": "WL9JpNV6fA_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(all_results, class1, class2):\n",
        "    print(f\"\\nClassification Results for {class1} vs {class2}:\\n\")\n",
        "    for feature_type, results in all_results.items():\n",
        "        print(f\"Feature Type: {feature_type}\")\n",
        "        for name, metrics in results.items():\n",
        "            print(f\"Classifier: {name}\")\n",
        "            print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "            print(f\"Sensitivity (Recall for Positive Class): {metrics['Sensitivity']:.4f}\")\n",
        "            print(f\"Specificity (Recall for Negative Class): {metrics['Specificity']:.4f}\")\n",
        "            print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
        "            print(f\"Matthews Correlation Coefficient: {metrics['Matthews Coefficient']:.4f}\")\n",
        "            print(f\"AUC: {metrics['AUC']:.4f}\")\n",
        "            print(f\"True Positives: {metrics['True Positive']}\")\n",
        "            print(f\"True Negatives: {metrics['True Negative']}\")\n",
        "            print(f\"False Positives: {metrics['False Positive']}\")\n",
        "            print(f\"False Negatives: {metrics['False Negative']}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the classes you want to compare\n",
        "    class1 = 's'\n",
        "    class2 = 'z'\n",
        "\n",
        "    # Run the binary classification with neural network models\n",
        "    all_results = run_binary_classification_nn(class1, class2)\n",
        "\n",
        "    # Display the results\n",
        "    display_results(all_results, class1, class2)\n"
      ],
      "metadata": {
        "id": "2t4HalMEe3B2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5731ef-00b1-4734-f041-97e179d1c05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EEG data from /content/drive/MyDrive/Database/Bonn Univ Dataset/s/S/\n",
            "Number of files loaded: 100\n",
            "Segmenting and preprocessing data for label: s\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Loading EEG data from /content/drive/MyDrive/Database/Bonn Univ Dataset/z/Z/\n",
            "Number of files loaded: 100\n",
            "Segmenting and preprocessing data for label: z\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Training LSTM model with normal features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4844 - loss: 0.6911 - val_accuracy: 0.5653 - val_loss: 0.6888\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5731 - loss: 0.6711 - val_accuracy: 0.5966 - val_loss: 0.6686\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5971 - loss: 0.6613 - val_accuracy: 0.6051 - val_loss: 0.6563\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6002 - loss: 0.6484 - val_accuracy: 0.5966 - val_loss: 0.6587\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5991 - loss: 0.6537 - val_accuracy: 0.6406 - val_loss: 0.6565\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6315 - loss: 0.6414 - val_accuracy: 0.5781 - val_loss: 0.6789\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6218 - loss: 0.6520 - val_accuracy: 0.6449 - val_loss: 0.6347\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6555 - loss: 0.6179 - val_accuracy: 0.6293 - val_loss: 0.6368\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6488 - loss: 0.6128 - val_accuracy: 0.6548 - val_loss: 0.6089\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6469 - loss: 0.6235 - val_accuracy: 0.6520 - val_loss: 0.6130\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Training Bi-LSTM model with normal features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.5306 - loss: 0.6887 - val_accuracy: 0.5554 - val_loss: 0.6868\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.5701 - loss: 0.6769 - val_accuracy: 0.5938 - val_loss: 0.6828\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6016 - loss: 0.6708 - val_accuracy: 0.6023 - val_loss: 0.6713\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6016 - loss: 0.6619 - val_accuracy: 0.6037 - val_loss: 0.6716\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6117 - loss: 0.6596 - val_accuracy: 0.6420 - val_loss: 0.6417\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6348 - loss: 0.6383 - val_accuracy: 0.6463 - val_loss: 0.6243\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6431 - loss: 0.6229 - val_accuracy: 0.6804 - val_loss: 0.5887\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7009 - loss: 0.5722 - val_accuracy: 0.6875 - val_loss: 0.5919\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7198 - loss: 0.5602 - val_accuracy: 0.6847 - val_loss: 0.5849\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6902 - loss: 0.5630 - val_accuracy: 0.7131 - val_loss: 0.5574\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Training GRU model with normal features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.5203 - loss: 0.6898 - val_accuracy: 0.5341 - val_loss: 0.6890\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.5432 - loss: 0.6871 - val_accuracy: 0.5724 - val_loss: 0.6841\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5704 - loss: 0.6745 - val_accuracy: 0.5866 - val_loss: 0.6754\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5753 - loss: 0.6699 - val_accuracy: 0.6562 - val_loss: 0.6486\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6540 - loss: 0.6380 - val_accuracy: 0.6662 - val_loss: 0.6369\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6878 - loss: 0.6182 - val_accuracy: 0.6903 - val_loss: 0.6042\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6814 - loss: 0.5938 - val_accuracy: 0.6804 - val_loss: 0.5969\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6955 - loss: 0.5830 - val_accuracy: 0.6875 - val_loss: 0.5981\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7076 - loss: 0.5716 - val_accuracy: 0.6804 - val_loss: 0.5838\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6968 - loss: 0.5706 - val_accuracy: 0.7017 - val_loss: 0.5749\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Training Transformer model with normal features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5084 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6933\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5030 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5113 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5098 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4995 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5058 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5036 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5184 - loss: 0.6928 - val_accuracy: 0.4759 - val_loss: 0.6939\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5128 - loss: 0.6929 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5020 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training LSTM model with lpc features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5983 - loss: 0.6697 - val_accuracy: 0.8026 - val_loss: 0.4523\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7730 - loss: 0.4752 - val_accuracy: 0.8182 - val_loss: 0.4172\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8219 - loss: 0.3879 - val_accuracy: 0.8011 - val_loss: 0.4615\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8164 - loss: 0.3953 - val_accuracy: 0.8196 - val_loss: 0.3874\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8433 - loss: 0.3428 - val_accuracy: 0.8366 - val_loss: 0.3638\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8360 - loss: 0.3450 - val_accuracy: 0.8253 - val_loss: 0.3713\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8472 - loss: 0.3642 - val_accuracy: 0.8324 - val_loss: 0.3649\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8389 - loss: 0.3445 - val_accuracy: 0.8310 - val_loss: 0.3678\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8328 - loss: 0.3605 - val_accuracy: 0.8452 - val_loss: 0.3469\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8376 - loss: 0.3547 - val_accuracy: 0.8452 - val_loss: 0.3477\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Bi-LSTM model with lpc features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.6380 - loss: 0.6450 - val_accuracy: 0.8295 - val_loss: 0.4220\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8378 - loss: 0.3695 - val_accuracy: 0.8395 - val_loss: 0.3833\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.8336 - loss: 0.3834 - val_accuracy: 0.8267 - val_loss: 0.3925\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8312 - loss: 0.3779 - val_accuracy: 0.8011 - val_loss: 0.4142\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8333 - loss: 0.3531 - val_accuracy: 0.8352 - val_loss: 0.3670\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8317 - loss: 0.3639 - val_accuracy: 0.8395 - val_loss: 0.3663\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8413 - loss: 0.3469 - val_accuracy: 0.8125 - val_loss: 0.4128\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8324 - loss: 0.3582 - val_accuracy: 0.8352 - val_loss: 0.3596\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8528 - loss: 0.3370 - val_accuracy: 0.8352 - val_loss: 0.3755\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.8525 - loss: 0.3313 - val_accuracy: 0.8452 - val_loss: 0.3609\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Training GRU model with lpc features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.6952 - loss: 0.6219 - val_accuracy: 0.8026 - val_loss: 0.4311\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8362 - loss: 0.3669 - val_accuracy: 0.8011 - val_loss: 0.4164\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8280 - loss: 0.3773 - val_accuracy: 0.8324 - val_loss: 0.3829\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8427 - loss: 0.3641 - val_accuracy: 0.8438 - val_loss: 0.3637\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8410 - loss: 0.3634 - val_accuracy: 0.8295 - val_loss: 0.3657\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8382 - loss: 0.3524 - val_accuracy: 0.8338 - val_loss: 0.3626\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8543 - loss: 0.3354 - val_accuracy: 0.8054 - val_loss: 0.4166\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8321 - loss: 0.3576 - val_accuracy: 0.8310 - val_loss: 0.3629\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8662 - loss: 0.3181 - val_accuracy: 0.8366 - val_loss: 0.3612\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8491 - loss: 0.3378 - val_accuracy: 0.8438 - val_loss: 0.3578\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Transformer model with lpc features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.4872 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6932\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5114 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6934\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5118 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5067 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5186 - loss: 0.6929 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5099 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5158 - loss: 0.6929 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5104 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5115 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5105 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training LSTM model with cepstral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.5217 - loss: 0.6901 - val_accuracy: 0.5355 - val_loss: 0.6912\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6084 - loss: 0.6721 - val_accuracy: 0.6349 - val_loss: 0.6628\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6395 - loss: 0.6448 - val_accuracy: 0.6222 - val_loss: 0.6533\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6578 - loss: 0.6218 - val_accuracy: 0.6307 - val_loss: 0.6395\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6723 - loss: 0.6103 - val_accuracy: 0.6307 - val_loss: 0.6413\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6635 - loss: 0.6131 - val_accuracy: 0.6293 - val_loss: 0.6430\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6608 - loss: 0.6143 - val_accuracy: 0.6264 - val_loss: 0.6474\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6640 - loss: 0.6064 - val_accuracy: 0.6364 - val_loss: 0.6473\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6743 - loss: 0.6026 - val_accuracy: 0.6378 - val_loss: 0.6431\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6606 - loss: 0.6129 - val_accuracy: 0.6321 - val_loss: 0.6500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Bi-LSTM model with cepstral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.4969 - loss: 0.6925 - val_accuracy: 0.5270 - val_loss: 0.6855\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6052 - loss: 0.6767 - val_accuracy: 0.5312 - val_loss: 0.7180\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6088 - loss: 0.6579 - val_accuracy: 0.6207 - val_loss: 0.6493\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6559 - loss: 0.6196 - val_accuracy: 0.6307 - val_loss: 0.6470\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.6809 - loss: 0.6036 - val_accuracy: 0.6264 - val_loss: 0.6581\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6595 - loss: 0.6209 - val_accuracy: 0.6222 - val_loss: 0.6565\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6700 - loss: 0.6145 - val_accuracy: 0.6307 - val_loss: 0.6480\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6753 - loss: 0.5995 - val_accuracy: 0.6293 - val_loss: 0.6420\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6750 - loss: 0.6039 - val_accuracy: 0.6264 - val_loss: 0.6389\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6516 - loss: 0.6171 - val_accuracy: 0.6335 - val_loss: 0.6407\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Training GRU model with cepstral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.5147 - loss: 0.6907 - val_accuracy: 0.6122 - val_loss: 0.6815\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6391 - loss: 0.6591 - val_accuracy: 0.6080 - val_loss: 0.6623\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6411 - loss: 0.6359 - val_accuracy: 0.6321 - val_loss: 0.6385\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6545 - loss: 0.6286 - val_accuracy: 0.6051 - val_loss: 0.6447\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6543 - loss: 0.6191 - val_accuracy: 0.6321 - val_loss: 0.6437\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6539 - loss: 0.6285 - val_accuracy: 0.6264 - val_loss: 0.6492\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6601 - loss: 0.6220 - val_accuracy: 0.6165 - val_loss: 0.6420\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6603 - loss: 0.6126 - val_accuracy: 0.6207 - val_loss: 0.6558\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6615 - loss: 0.6113 - val_accuracy: 0.6378 - val_loss: 0.6550\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6843 - loss: 0.5975 - val_accuracy: 0.6335 - val_loss: 0.6393\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Training Transformer model with cepstral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4947 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6933\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5008 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6934\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5075 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5057 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5070 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5069 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5126 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6938\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4975 - loss: 0.6933 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5076 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6938\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5229 - loss: 0.6927 - val_accuracy: 0.4759 - val_loss: 0.6938\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training LSTM model with inverse_filter features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8580 - loss: 0.4825 - val_accuracy: 0.9219 - val_loss: 0.2253\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9220 - loss: 0.2208 - val_accuracy: 0.9219 - val_loss: 0.2154\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9317 - loss: 0.1896 - val_accuracy: 0.9261 - val_loss: 0.2088\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9269 - loss: 0.2071 - val_accuracy: 0.9176 - val_loss: 0.2104\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9346 - loss: 0.1875 - val_accuracy: 0.9361 - val_loss: 0.1899\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9325 - loss: 0.1899 - val_accuracy: 0.9389 - val_loss: 0.1803\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9357 - loss: 0.1759 - val_accuracy: 0.9119 - val_loss: 0.2163\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9349 - loss: 0.1816 - val_accuracy: 0.9446 - val_loss: 0.1603\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9370 - loss: 0.1767 - val_accuracy: 0.9432 - val_loss: 0.1689\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9410 - loss: 0.1746 - val_accuracy: 0.9460 - val_loss: 0.1576\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Bi-LSTM model with inverse_filter features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.8357 - loss: 0.5263 - val_accuracy: 0.8949 - val_loss: 0.2540\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.9158 - loss: 0.2231 - val_accuracy: 0.9134 - val_loss: 0.2423\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9313 - loss: 0.1912 - val_accuracy: 0.9361 - val_loss: 0.1905\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9334 - loss: 0.1928 - val_accuracy: 0.9375 - val_loss: 0.1732\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9383 - loss: 0.1760 - val_accuracy: 0.9361 - val_loss: 0.1848\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9414 - loss: 0.1759 - val_accuracy: 0.9361 - val_loss: 0.1783\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.9397 - loss: 0.1618 - val_accuracy: 0.9403 - val_loss: 0.1737\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9367 - loss: 0.1713 - val_accuracy: 0.9247 - val_loss: 0.2051\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.9418 - loss: 0.1709 - val_accuracy: 0.9432 - val_loss: 0.1586\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9405 - loss: 0.1747 - val_accuracy: 0.9389 - val_loss: 0.1616\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Training GRU model with inverse_filter features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8507 - loss: 0.4855 - val_accuracy: 0.9190 - val_loss: 0.2117\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9276 - loss: 0.2060 - val_accuracy: 0.9304 - val_loss: 0.1960\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9424 - loss: 0.1679 - val_accuracy: 0.9361 - val_loss: 0.1786\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9245 - loss: 0.2052 - val_accuracy: 0.9389 - val_loss: 0.1687\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9448 - loss: 0.1688 - val_accuracy: 0.9418 - val_loss: 0.1763\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9421 - loss: 0.1667 - val_accuracy: 0.9418 - val_loss: 0.1682\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9411 - loss: 0.1637 - val_accuracy: 0.9403 - val_loss: 0.1656\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9298 - loss: 0.1871 - val_accuracy: 0.9446 - val_loss: 0.1606\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9444 - loss: 0.1551 - val_accuracy: 0.9247 - val_loss: 0.2060\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9420 - loss: 0.1608 - val_accuracy: 0.9446 - val_loss: 0.1602\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Transformer model with inverse_filter features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.4924 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6933\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5229 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6934\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4992 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6935\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5089 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4926 - loss: 0.6933 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4956 - loss: 0.6933 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4987 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5251 - loss: 0.6927 - val_accuracy: 0.4759 - val_loss: 0.6938\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4944 - loss: 0.6934 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training LSTM model with spectral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.5436 - loss: 0.6862 - val_accuracy: 0.5824 - val_loss: 0.6724\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6025 - loss: 0.6667 - val_accuracy: 0.5724 - val_loss: 0.6742\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5905 - loss: 0.6700 - val_accuracy: 0.5895 - val_loss: 0.6643\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5811 - loss: 0.6692 - val_accuracy: 0.5909 - val_loss: 0.6643\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5767 - loss: 0.6680 - val_accuracy: 0.5994 - val_loss: 0.6588\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6265 - loss: 0.6508 - val_accuracy: 0.6250 - val_loss: 0.6420\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6735 - loss: 0.6160 - val_accuracy: 0.7273 - val_loss: 0.5637\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6625 - loss: 0.5886 - val_accuracy: 0.6662 - val_loss: 0.6148\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7230 - loss: 0.5698 - val_accuracy: 0.7330 - val_loss: 0.5506\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7004 - loss: 0.5678 - val_accuracy: 0.7344 - val_loss: 0.5419\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Training Bi-LSTM model with spectral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.5478 - loss: 0.6846 - val_accuracy: 0.5824 - val_loss: 0.6806\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5680 - loss: 0.6767 - val_accuracy: 0.5781 - val_loss: 0.6691\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.5829 - loss: 0.6708 - val_accuracy: 0.5852 - val_loss: 0.6730\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5777 - loss: 0.6677 - val_accuracy: 0.5824 - val_loss: 0.6667\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5770 - loss: 0.6726 - val_accuracy: 0.6009 - val_loss: 0.7076\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.6053 - loss: 0.6701 - val_accuracy: 0.6037 - val_loss: 0.6578\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.6091 - loss: 0.6554 - val_accuracy: 0.6264 - val_loss: 0.6571\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6628 - loss: 0.6265 - val_accuracy: 0.7315 - val_loss: 0.5480\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.7331 - loss: 0.5293 - val_accuracy: 0.7259 - val_loss: 0.5590\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7446 - loss: 0.5160 - val_accuracy: 0.7287 - val_loss: 0.5429\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Training GRU model with spectral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5400 - loss: 0.6868 - val_accuracy: 0.5795 - val_loss: 0.6799\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5534 - loss: 0.6804 - val_accuracy: 0.5739 - val_loss: 0.6792\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5840 - loss: 0.6725 - val_accuracy: 0.5739 - val_loss: 0.6746\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5738 - loss: 0.6742 - val_accuracy: 0.5710 - val_loss: 0.6767\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5747 - loss: 0.6732 - val_accuracy: 0.5497 - val_loss: 0.6896\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5601 - loss: 0.6762 - val_accuracy: 0.5810 - val_loss: 0.6802\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5754 - loss: 0.6756 - val_accuracy: 0.5824 - val_loss: 0.6690\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5825 - loss: 0.6717 - val_accuracy: 0.5824 - val_loss: 0.6821\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5753 - loss: 0.6696 - val_accuracy: 0.5824 - val_loss: 0.6715\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5720 - loss: 0.6715 - val_accuracy: 0.5824 - val_loss: 0.6683\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Training Transformer model with spectral features\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5102 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6933\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5254 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6934\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5035 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6934\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5035 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5081 - loss: 0.6931 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5003 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6936\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5105 - loss: 0.6930 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5132 - loss: 0.6929 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4978 - loss: 0.6933 - val_accuracy: 0.4759 - val_loss: 0.6937\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5014 - loss: 0.6932 - val_accuracy: 0.4759 - val_loss: 0.6938\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "Classification Results for s vs z:\n",
            "\n",
            "Feature Type: normal\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.6909\n",
            "Sensitivity (Recall for Positive Class): 0.8318\n",
            "Specificity (Recall for Negative Class): 0.5500\n",
            "F1 Score: 0.7291\n",
            "Matthews Correlation Coefficient: 0.3979\n",
            "AUC: 0.7401\n",
            "True Positives: 366\n",
            "True Negatives: 242\n",
            "False Positives: 198\n",
            "False Negatives: 74\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.7227\n",
            "Sensitivity (Recall for Positive Class): 0.8727\n",
            "Specificity (Recall for Negative Class): 0.5727\n",
            "F1 Score: 0.7589\n",
            "Matthews Correlation Coefficient: 0.4670\n",
            "AUC: 0.7923\n",
            "True Positives: 384\n",
            "True Negatives: 252\n",
            "False Positives: 188\n",
            "False Negatives: 56\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.7068\n",
            "Sensitivity (Recall for Positive Class): 0.8773\n",
            "Specificity (Recall for Negative Class): 0.5364\n",
            "F1 Score: 0.7495\n",
            "Matthews Correlation Coefficient: 0.4400\n",
            "AUC: 0.7657\n",
            "True Positives: 386\n",
            "True Negatives: 236\n",
            "False Positives: 204\n",
            "False Negatives: 54\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 0.0000\n",
            "Specificity (Recall for Negative Class): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 0\n",
            "True Negatives: 440\n",
            "False Positives: 0\n",
            "False Negatives: 440\n",
            "--------------------------------------------------\n",
            "Feature Type: lpc\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.8614\n",
            "Sensitivity (Recall for Positive Class): 0.8909\n",
            "Specificity (Recall for Negative Class): 0.8318\n",
            "F1 Score: 0.8653\n",
            "Matthews Correlation Coefficient: 0.7240\n",
            "AUC: 0.9401\n",
            "True Positives: 392\n",
            "True Negatives: 366\n",
            "False Positives: 74\n",
            "False Negatives: 48\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.8523\n",
            "Sensitivity (Recall for Positive Class): 0.8182\n",
            "Specificity (Recall for Negative Class): 0.8864\n",
            "F1 Score: 0.8471\n",
            "Matthews Correlation Coefficient: 0.7062\n",
            "AUC: 0.9384\n",
            "True Positives: 360\n",
            "True Negatives: 390\n",
            "False Positives: 50\n",
            "False Negatives: 80\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.8614\n",
            "Sensitivity (Recall for Positive Class): 0.8409\n",
            "Specificity (Recall for Negative Class): 0.8818\n",
            "F1 Score: 0.8585\n",
            "Matthews Correlation Coefficient: 0.7233\n",
            "AUC: 0.9418\n",
            "True Positives: 370\n",
            "True Negatives: 388\n",
            "False Positives: 52\n",
            "False Negatives: 70\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 0.0000\n",
            "Specificity (Recall for Negative Class): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 0\n",
            "True Negatives: 440\n",
            "False Positives: 0\n",
            "False Negatives: 440\n",
            "--------------------------------------------------\n",
            "Feature Type: cepstral\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.6136\n",
            "Sensitivity (Recall for Positive Class): 0.5705\n",
            "Specificity (Recall for Negative Class): 0.6568\n",
            "F1 Score: 0.5962\n",
            "Matthews Correlation Coefficient: 0.2281\n",
            "AUC: 0.6930\n",
            "True Positives: 251\n",
            "True Negatives: 289\n",
            "False Positives: 151\n",
            "False Negatives: 189\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.6136\n",
            "Sensitivity (Recall for Positive Class): 0.5750\n",
            "Specificity (Recall for Negative Class): 0.6523\n",
            "F1 Score: 0.5981\n",
            "Matthews Correlation Coefficient: 0.2280\n",
            "AUC: 0.6908\n",
            "True Positives: 253\n",
            "True Negatives: 287\n",
            "False Positives: 153\n",
            "False Negatives: 187\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.6205\n",
            "Sensitivity (Recall for Positive Class): 0.6091\n",
            "Specificity (Recall for Negative Class): 0.6318\n",
            "F1 Score: 0.6161\n",
            "Matthews Correlation Coefficient: 0.2410\n",
            "AUC: 0.6885\n",
            "True Positives: 268\n",
            "True Negatives: 278\n",
            "False Positives: 162\n",
            "False Negatives: 172\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 0.0000\n",
            "Specificity (Recall for Negative Class): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 0\n",
            "True Negatives: 440\n",
            "False Positives: 0\n",
            "False Negatives: 440\n",
            "--------------------------------------------------\n",
            "Feature Type: inverse_filter\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.9364\n",
            "Sensitivity (Recall for Positive Class): 0.9568\n",
            "Specificity (Recall for Negative Class): 0.9159\n",
            "F1 Score: 0.9376\n",
            "Matthews Correlation Coefficient: 0.8735\n",
            "AUC: 0.9781\n",
            "True Positives: 421\n",
            "True Negatives: 403\n",
            "False Positives: 37\n",
            "False Negatives: 19\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.9330\n",
            "Sensitivity (Recall for Positive Class): 0.9477\n",
            "Specificity (Recall for Negative Class): 0.9182\n",
            "F1 Score: 0.9339\n",
            "Matthews Correlation Coefficient: 0.8663\n",
            "AUC: 0.9778\n",
            "True Positives: 417\n",
            "True Negatives: 404\n",
            "False Positives: 36\n",
            "False Negatives: 23\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.9352\n",
            "Sensitivity (Recall for Positive Class): 0.9523\n",
            "Specificity (Recall for Negative Class): 0.9182\n",
            "F1 Score: 0.9363\n",
            "Matthews Correlation Coefficient: 0.8710\n",
            "AUC: 0.9757\n",
            "True Positives: 419\n",
            "True Negatives: 404\n",
            "False Positives: 36\n",
            "False Negatives: 21\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 0.0000\n",
            "Specificity (Recall for Negative Class): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 0\n",
            "True Negatives: 440\n",
            "False Positives: 0\n",
            "False Negatives: 440\n",
            "--------------------------------------------------\n",
            "Feature Type: spectral\n",
            "Classifier: LSTM\n",
            "Accuracy: 0.7466\n",
            "Sensitivity (Recall for Positive Class): 0.8773\n",
            "Specificity (Recall for Negative Class): 0.6159\n",
            "F1 Score: 0.7759\n",
            "Matthews Correlation Coefficient: 0.5109\n",
            "AUC: 0.8042\n",
            "True Positives: 386\n",
            "True Negatives: 271\n",
            "False Positives: 169\n",
            "False Negatives: 54\n",
            "--------------------------------------------------\n",
            "Classifier: Bi-LSTM\n",
            "Accuracy: 0.7455\n",
            "Sensitivity (Recall for Positive Class): 0.9068\n",
            "Specificity (Recall for Negative Class): 0.5841\n",
            "F1 Score: 0.7808\n",
            "Matthews Correlation Coefficient: 0.5187\n",
            "AUC: 0.8196\n",
            "True Positives: 399\n",
            "True Negatives: 257\n",
            "False Positives: 183\n",
            "False Negatives: 41\n",
            "--------------------------------------------------\n",
            "Classifier: GRU\n",
            "Accuracy: 0.5920\n",
            "Sensitivity (Recall for Positive Class): 0.8091\n",
            "Specificity (Recall for Negative Class): 0.3750\n",
            "F1 Score: 0.6648\n",
            "Matthews Correlation Coefficient: 0.2043\n",
            "AUC: 0.6139\n",
            "True Positives: 356\n",
            "True Negatives: 165\n",
            "False Positives: 275\n",
            "False Negatives: 84\n",
            "--------------------------------------------------\n",
            "Classifier: Transformer\n",
            "Accuracy: 0.5000\n",
            "Sensitivity (Recall for Positive Class): 0.0000\n",
            "Specificity (Recall for Negative Class): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC: 0.5000\n",
            "True Positives: 0\n",
            "True Negatives: 440\n",
            "False Positives: 0\n",
            "False Negatives: 440\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Function to run unsupervised learning algorithms\n",
        "def run_unsupervised_learning(class1, class2):\n",
        "    all_segments, all_labels = [], []\n",
        "    for label in [class1, class2]:\n",
        "        path = base_paths[label]\n",
        "        eeg_data = load_eeg_data(path)\n",
        "        segments, labels = segment_and_preprocess(eeg_data, label)\n",
        "        all_segments.extend(segments)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    label_mapping = {class1: 0, class2: 1}\n",
        "    all_labels = [label_mapping[label] for label in all_labels]\n",
        "\n",
        "    # Define feature types\n",
        "    feature_types = ['normal', 'lpc', 'cepstral', 'inverse_filter', 'spectral']\n",
        "\n",
        "    # Initialize results\n",
        "    all_results = {}\n",
        "\n",
        "    for feature_type in feature_types:\n",
        "        # Extract features from segments\n",
        "        features = extract_features_from_segments(all_segments, feature_type)\n",
        "\n",
        "        # Handle missing values using SimpleImputer\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        features = imputer.fit_transform(features)\n",
        "\n",
        "        # Standardize features\n",
        "        scaler = StandardScaler()\n",
        "        features = scaler.fit_transform(features)\n",
        "\n",
        "        # Initialize unsupervised learning models\n",
        "        models = {\n",
        "            'K-Means': KMeans(n_clusters=2),\n",
        "            'Hierarchical Clustering': AgglomerativeClustering(n_clusters=2),\n",
        "            'DBSCAN': DBSCAN(),\n",
        "            'GMM': GaussianMixture(n_components=2)\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            print(f\"Running {name} on {feature_type} features\")\n",
        "            model.fit(features)\n",
        "            if hasattr(model, 'labels_'):\n",
        "                labels = model.labels_\n",
        "            else:\n",
        "                labels = model.predict(features)\n",
        "            silhouette_avg = silhouette_score(features, labels)\n",
        "            results[name] = {\n",
        "                'Silhouette Score': silhouette_avg\n",
        "            }\n",
        "\n",
        "        all_results[feature_type] = results\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# New function to display results\n",
        "def display_unsupervised_learning(all_results, class1, class2):\n",
        "    for feature_type, results in all_results.items():\n",
        "        print(f\"\\nResults for {feature_type} features:\")\n",
        "        for model_name, metrics in results.items():\n",
        "            print(f\"{model_name}:\")\n",
        "            for metric, value in metrics.items():\n",
        "                print(f\"  {metric}: {value}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the classes you want to compare\n",
        "    class1 = 's'\n",
        "    class2 = 'z'\n",
        "\n",
        "    # Run the unsupervised learning algorithms\n",
        "    all_results = run_unsupervised_learning(class1, class2)\n",
        "\n",
        "    # Display the results using the new function\n",
        "    display_unsupervised_learning(all_results, class1, class2)\n"
      ],
      "metadata": {
        "id": "quKd68BQm-DG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e26281b-c892-4a73-e999-1e9209173f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EEG data from /content/drive/MyDrive/Database/Bonn Univ Dataset/s/S/\n",
            "Number of files loaded: 100\n",
            "Segmenting and preprocessing data for label: s\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Loading EEG data from /content/drive/MyDrive/Database/Bonn Univ Dataset/z/Z/\n",
            "Number of files loaded: 100\n",
            "Segmenting and preprocessing data for label: z\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Number of segments created: 22\n",
            "Running K-Means on normal features\n",
            "Running Hierarchical Clustering on normal features\n",
            "Running DBSCAN on normal features\n",
            "Running GMM on normal features\n",
            "Running K-Means on lpc features\n",
            "Running Hierarchical Clustering on lpc features\n",
            "Running DBSCAN on lpc features\n",
            "Running GMM on lpc features\n",
            "Running K-Means on cepstral features\n",
            "Running Hierarchical Clustering on cepstral features\n",
            "Running DBSCAN on cepstral features\n",
            "Running GMM on cepstral features\n",
            "Running K-Means on inverse_filter features\n",
            "Running Hierarchical Clustering on inverse_filter features\n",
            "Running DBSCAN on inverse_filter features\n",
            "Running GMM on inverse_filter features\n",
            "Running K-Means on spectral features\n",
            "Running Hierarchical Clustering on spectral features\n",
            "Running DBSCAN on spectral features\n",
            "Running GMM on spectral features\n",
            "\n",
            "Results for normal features:\n",
            "K-Means:\n",
            "  Silhouette Score: 0.2597662796708754\n",
            "Hierarchical Clustering:\n",
            "  Silhouette Score: 0.257251344592649\n",
            "DBSCAN:\n",
            "  Silhouette Score: -0.04515801703611734\n",
            "GMM:\n",
            "  Silhouette Score: 0.21406003452373779\n",
            "\n",
            "Results for lpc features:\n",
            "K-Means:\n",
            "  Silhouette Score: 0.3427048734084745\n",
            "Hierarchical Clustering:\n",
            "  Silhouette Score: 0.3098939842796729\n",
            "DBSCAN:\n",
            "  Silhouette Score: -0.03755257210890212\n",
            "GMM:\n",
            "  Silhouette Score: 0.3213539168520522\n",
            "\n",
            "Results for cepstral features:\n",
            "K-Means:\n",
            "  Silhouette Score: 0.39936783565032474\n",
            "Hierarchical Clustering:\n",
            "  Silhouette Score: 0.31687123455693716\n",
            "DBSCAN:\n",
            "  Silhouette Score: -0.06991195072871312\n",
            "GMM:\n",
            "  Silhouette Score: 0.3842632878906575\n",
            "\n",
            "Results for inverse_filter features:\n",
            "K-Means:\n",
            "  Silhouette Score: 0.3737347427583822\n",
            "Hierarchical Clustering:\n",
            "  Silhouette Score: 0.36308117387770145\n",
            "DBSCAN:\n",
            "  Silhouette Score: 0.16137690629474719\n",
            "GMM:\n",
            "  Silhouette Score: 0.2883679384117244\n",
            "\n",
            "Results for spectral features:\n",
            "K-Means:\n",
            "  Silhouette Score: 0.2728862653690202\n",
            "Hierarchical Clustering:\n",
            "  Silhouette Score: 0.1759273642752617\n",
            "DBSCAN:\n",
            "  Silhouette Score: -0.2624682711534029\n",
            "GMM:\n",
            "  Silhouette Score: 0.2008759300524675\n"
          ]
        }
      ]
    }
  ]
}
